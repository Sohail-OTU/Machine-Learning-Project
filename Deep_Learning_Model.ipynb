{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anti-Fraud Model** by *Sohail, Ahmed,* and *Hiten*\n",
    "\n",
    "---\n",
    "\n",
    "Using a **Feedforward Neural Network (FNN)** because our dataset is structured and tabular.\n",
    "\n",
    "Our initial goal was that...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING NECESSARY LIBRARIES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATASET\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Dataset\\Cleaned_AntiFraud_Centre_Dataset.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(f\"\\n\\n{df.describe(include='all')}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Data type of each column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------ **Graphing and Analysis of Raw Data** --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH AND ANALYSIS\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Dataset\\Cleaned_AntiFraud_Centre_Dataset.csv')\n",
    "\n",
    "# Statistical Summary of the dataset, some of the outputs are for numerical features only \n",
    "# so it will result in a value of NaN in the categorical features output\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Our target is \"Complaint Type\". A victim = a fraud case and others are not fraud cases.\n",
    "sns.countplot(x='Complaint Type', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO SEE CORRELATION OF FEATURES - TARGET\n",
    "# FUNCTION WILL PRINT 9 GRAPHS\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Dataset\\Cleaned_AntiFraud_Centre_Dataset.csv')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_target_correlation(df, columns, target, top_n=10):\n",
    "    for col in columns:\n",
    "        \n",
    "        top_categories = df[col].value_counts().nlargest(top_n).index\n",
    "        filtered_df = df[df[col].isin(top_categories)]\n",
    "        \n",
    "        sns.countplot(x=col, hue=target, data=filtered_df)\n",
    "        plt.title(f\" Top {top_n} {col} vs {target}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "columns = ['Date Received', 'Complaint Received Type', 'Country', 'Province/State', 'Fraud and Cybercrime Thematic Categories', \n",
    "           'Solicitation Method', 'Gender', 'Language of Correspondence', 'Victim Age Range']\n",
    "\n",
    "target = 'Complaint Type'\n",
    "\n",
    "plot_feature_target_correlation(df, columns, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEWING TARGET VARIABLE STATISTICS\n",
    "\n",
    "print(df[\"Complaint Type\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------- **Pre-processing and Handling Missing Data** ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv('Dataset\\Cleaned_AntiFraud_Centre_Dataset.csv')\n",
    "\n",
    "## [--HANDLING MISSING DATA--]---------------------------------------\n",
    "\n",
    "# Convert Not Specified, Not Available, etc. into NaN value\n",
    "df.replace([\"Not Specified\", \"Not Available / non disponible\", \"Not Available\"], pd.NA, inplace=True)\n",
    "\n",
    "# Change NaN values of Province/State to Unknown\n",
    "df['Province/State'] = df['Province/State'].fillna('Unknown')\n",
    "\n",
    "# Change NaN Values of Country to Unknown\n",
    "df['Country'] = df['Country'].fillna('Unknown')\n",
    "\n",
    "# Change NaN Values of Solicitation Method to mode (most frequent value) to minimize\n",
    "# missingness and reduce bias\n",
    "mode_solicitation = df[\"Solicitation Method\"].mode()[0]\n",
    "df[\"Solicitation Method\"] = df[\"Solicitation Method\"].fillna(mode_solicitation)\n",
    "\n",
    "# Change Gender NaN values to Unknown\n",
    "df['Gender'] = df['Gender'].fillna('Unknown')\n",
    "\n",
    "# Change Language of Correspondence NaN values to Unknown\n",
    "df['Language of Correspondence'] = df['Language of Correspondence'].fillna('Unknown')\n",
    "\n",
    "# Convert $x.xx to float number and replace missing values or 0 with a computed mean.\n",
    "df[\"Dollar Loss\"] = df[\"Dollar Loss\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df[\"Dollar Loss\"] = df[\"Dollar Loss\"].fillna(df[\"Dollar Loss\"].mean())\n",
    "\n",
    "\n",
    "## [--EXTRACTING DATE FEATURES--]-------------------------------------------------------\n",
    "\n",
    "# Convert to DateTime format\n",
    "df['Date Received'] = pd.to_datetime(df['Date Received'], errors='coerce')\n",
    "\n",
    "# Create new features \"Year\", \"Month\", \"Day\", and \"DayOfTheWeek\"\n",
    "df['Year'] = df['Date Received'].dt.year\n",
    "df['Month'] = df['Date Received'].dt.month\n",
    "df['Day'] = df['Date Received'].dt.day\n",
    "df['DayOfTheWeek'] = df['Date Received'].dt.dayofweek\n",
    "\n",
    "\n",
    "## [--VICTIM AGE RANGE TO ORDINAL VARIABLE--]---------------------------------------------------\n",
    "\n",
    "age_order = {\n",
    "    \"'Not Available / non disponible\": 0,\n",
    "    \"'Under 20\": 1,\n",
    "    \"'20 - 29\": 2,\n",
    "    \"'30 - 39\": 3,\n",
    "    \"'40 - 49\": 4,\n",
    "    \"'50 - 59\": 5,\n",
    "    \"'60 - 69\": 6,\n",
    "    \"'70 - 79\": 7,\n",
    "    \"'80 and over\": 8\n",
    "}\n",
    "\n",
    "df[\"Victim Age Range\"] = df[\"Victim Age Range\"].map(age_order)\n",
    "\n",
    "## [--TARGET VAIRABLE --> BINARY--]---------------------------------------------------------------\n",
    "\n",
    "df['Is_Fraud'] = df['Complaint Type'].apply(lambda x: 1 if x.strip() == 'Victim' else 0)\n",
    "\n",
    "## [--DROPPING UNNECESSARY COLUMNS--]-------------------------\n",
    "cols_to_drop = [\n",
    "    \"Number ID\",        # Just an identifier no real impact\n",
    "    \"Complaint Type\",   # Redundant because we are changed it to binary\n",
    "    \"Date Received\",    # Already split into year, day, month, and day of the week\n",
    "]\n",
    "\n",
    "df = df.drop(columns = cols_to_drop, axis=1)\n",
    "\n",
    "## [--SCALING NUMERICAL VARIABLES--]--------------------------------------------------------------------\n",
    "\n",
    "# Fixing cyclic variables to reflect actual cycles (months, days of the week)\n",
    "df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "df['DayOfTheWeek_sin'] = np.sin(2 * np.pi * df['DayOfTheWeek'] / 7)\n",
    "df['DayOfTheWeek_cos'] = np.cos(2 * np.pi * df['DayOfTheWeek'] / 7)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_features = ['Victim Age Range', 'Number of Victims', 'Dollar Loss', 'Year', 'Month_sin', 'Month_cos', 'DayOfTheWeek_sin', 'DayOfTheWeek_cos' ]\n",
    "\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------- **Splitting Into Training and Testing Split** -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from category_encoders import TargetEncoder \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "## [--DEFINING THE TESTING/TRAINING SPLIT--]-------------------------------------------------\n",
    "\n",
    "x = df.drop(columns=[\"Is_Fraud\"])\n",
    "y = df[\"Is_Fraud\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "## [--TARGET ENCODING \"COUNTRY\" (HIGH CARDINALITY)--]----------------------------------------\n",
    "\n",
    "encoder = TargetEncoder()\n",
    "x_train[\"Country\"] = encoder.fit_transform(x_train[\"Country\"], y_train)\n",
    "\n",
    "x_test[\"Country\"] = encoder.transform(x_test[\"Country\"])\n",
    "\n",
    "## [--LABEL ENCODING CATEGORICAL VARIABLES]--------------------------------------------------\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "x_train[\"Province/State\"] = label_encoder.fit_transform(x_train[\"Province/State\"], y_train)\n",
    "x_train[\"Complaint Received Type\"] = label_encoder.fit_transform(x_train[\"Complaint Received Type\"], y_train)\n",
    "x_train[\"Gender\"] = label_encoder.fit_transform(x_train[\"Gender\"], y_train)\n",
    "x_train[\"Fraud and Cybercrime Thematic Categories\"] = label_encoder.fit_transform(x_train[\"Fraud and Cybercrime Thematic Categories\"], y_train)\n",
    "x_train[\"Solicitation Method\"] = label_encoder.fit_transform(x_train[\"Solicitation Method\"], y_train)\n",
    "x_train[\"Language of Correspondence\"] = label_encoder.fit_transform(x_train[\"Language of Correspondence\"], y_train)\n",
    "\n",
    "x_test[\"Province/State\"] = label_encoder.transform(x_test[\"Province/State\"])\n",
    "x_test[\"Complaint Received Type\"] = label_encoder.transform(x_test[\"Complaint Received Type\"])\n",
    "x_test[\"Gender\"] = label_encoder.transform(x_test[\"Gender\"])\n",
    "x_test[\"Fraud and Cybercrime Thematic Categories\"] = label_encoder.transform(x_test[\"Fraud and Cybercrime Thematic Categories\"])\n",
    "x_test[\"Solicitation Method\"] = label_encoder.transform(x_test[\"Solicitation Method\"])\n",
    "x_test[\"Language of Correspondence\"] = label_encoder.transform(x_test[\"Language of Correspondence\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------- **Building a Deep Learning FNN Model** --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Complaint Received Type Country Province/State  \\\n",
      "count                   313976  313976         313976   \n",
      "unique                      10     154             66   \n",
      "top               CAFC Website  Canada        Ontario   \n",
      "freq                    164920  238635          91683   \n",
      "mean                       NaN     NaN            NaN   \n",
      "std                        NaN     NaN            NaN   \n",
      "min                        NaN     NaN            NaN   \n",
      "25%                        NaN     NaN            NaN   \n",
      "50%                        NaN     NaN            NaN   \n",
      "75%                        NaN     NaN            NaN   \n",
      "max                        NaN     NaN            NaN   \n",
      "\n",
      "       Fraud and Cybercrime Thematic Categories Solicitation Method  Gender  \\\n",
      "count                                    313976              313976  313976   \n",
      "unique                                       39                  13       5   \n",
      "top                              Identity Fraud       Other/unknown  Female   \n",
      "freq                                      72417              108553  118866   \n",
      "mean                                        NaN                 NaN     NaN   \n",
      "std                                         NaN                 NaN     NaN   \n",
      "min                                         NaN                 NaN     NaN   \n",
      "25%                                         NaN                 NaN     NaN   \n",
      "50%                                         NaN                 NaN     NaN   \n",
      "75%                                         NaN                 NaN     NaN   \n",
      "max                                         NaN                 NaN     NaN   \n",
      "\n",
      "       Language of Correspondence  Victim Age Range  Number of Victims  \\\n",
      "count                      313976     295871.000000      313976.000000   \n",
      "unique                          3               NaN                NaN   \n",
      "top                       English               NaN                NaN   \n",
      "freq                       173612               NaN                NaN   \n",
      "mean                          NaN          2.952263           0.645100   \n",
      "std                           NaN          2.417519           0.478484   \n",
      "min                           NaN          0.000000           0.000000   \n",
      "25%                           NaN          0.000000           0.000000   \n",
      "50%                           NaN          3.000000           1.000000   \n",
      "75%                           NaN          5.000000           1.000000   \n",
      "max                           NaN          7.000000           1.000000   \n",
      "\n",
      "         Dollar Loss           Year          Month            Day  \\\n",
      "count   3.139760e+05  313976.000000  313976.000000  313976.000000   \n",
      "unique           NaN            NaN            NaN            NaN   \n",
      "top              NaN            NaN            NaN            NaN   \n",
      "freq             NaN            NaN            NaN            NaN   \n",
      "mean    6.787552e+03    2022.174067       6.304549      15.459745   \n",
      "std     1.031143e+05       1.069735       3.447961       8.792716   \n",
      "min     0.000000e+00    2021.000000       1.000000       1.000000   \n",
      "25%     0.000000e+00    2021.000000       3.000000       8.000000   \n",
      "50%     0.000000e+00    2022.000000       6.000000      15.000000   \n",
      "75%     0.000000e+00    2023.000000       9.000000      23.000000   \n",
      "max     2.361500e+07    2024.000000      12.000000      31.000000   \n",
      "\n",
      "         DayOfTheWeek       Is_Fraud  \n",
      "count   313976.000000  313976.000000  \n",
      "unique            NaN            NaN  \n",
      "top               NaN            NaN  \n",
      "freq              NaN            NaN  \n",
      "mean         2.253857       0.645100  \n",
      "std          1.634696       0.478484  \n",
      "min          0.000000       0.000000  \n",
      "25%          1.000000       0.000000  \n",
      "50%          2.000000       1.000000  \n",
      "75%          3.000000       1.000000  \n",
      "max          6.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "\n",
    "## DEFINE INPUT LAYERS\n",
    "\n",
    "province_input = Input(shape=(1,), name=\"Province/State\")\n",
    "country_input = Input(shape=(1,), name=\"Country\")    \n",
    "dollar_loss_input = Input(shape=(1,), name=\"Dollar Loss\")\n",
    "victim_age_range_input = Input(shape=(1,), name=\"Victim Age Range\")\n",
    "complaint_received_type_input = Input(shape=(1,), name=\"Complaint Received Type\")\n",
    "fraud_and_cybercrime_category_input = Input(shape=(1,), name=\"Fraud and Cybercrime Thematic Categories\")\n",
    "solicitation_input = Input(shape=(1,), name=\"Solicitation Method\")\n",
    "gender_input = Input(shape=(1,), name=\"Gender\")\n",
    "number_of_victims_input = Input(shape=(1,), name=\"Number of Victims\")\n",
    "year_input = Input(shape=(1,), name=\"Year\")\n",
    "month_sin_input = Input(shape=(1,), name=\"Month_sin\")\n",
    "month_cos_input = Input(shape=(1,), name=\"Month_cos\")\n",
    "dayoftheweek_sin_input = Input(shape=(1,), name=\"DayOfTheWeek_sin\")\n",
    "dayoftheweek_cos_input = Input(shape=(1,), name=\"DayOfTheWeek_cos\")\n",
    "day_input = Input(shape=(1,), name=\"Day\")\n",
    "\n",
    "# CONECTATE ALL INPUTS\n",
    "all_inputs = Concatenate()([\n",
    "    province_input,\n",
    "    country_input,\n",
    "    dollar_loss_input,\n",
    "    victim_age_range_input,\n",
    "    complaint_received_type_input,\n",
    "    fraud_and_cybercrime_category_input,\n",
    "    solicitation_input,\n",
    "    gender_input,\n",
    "    number_of_victims_input,\n",
    "    year_input,\n",
    "    month_sin_input,\n",
    "    month_cos_input,\n",
    "    dayoftheweek_sin_input,\n",
    "    dayoftheweek_cos_input,\n",
    "    day_input\n",
    "])\n",
    "\n",
    "# DEFINE HIDDEN LAYERS\n",
    "x = Dense(128, activation='relu')(all_inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# OUTPUT LAYER\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
